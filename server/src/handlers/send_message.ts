
import { db } from '../db';
import { chatsTable, messagesTable, nelsonContentTable } from '../db/schema';
import { type SendMessageInput, type AIResponse } from '../schema';
import { eq, and, ilike } from 'drizzle-orm';

export async function sendMessage(input: SendMessageInput): Promise<AIResponse> {
  const startTime = Date.now();
  
  try {
    // 1. Verify chat exists and belongs to user
    const chat = await db.select()
      .from(chatsTable)
      .where(and(
        eq(chatsTable.id, input.chat_id),
        eq(chatsTable.user_id, input.user_id)
      ))
      .execute();

    if (chat.length === 0) {
      throw new Error('Chat not found or access denied');
    }

    // 2. Save user message to database
    const userMessageResult = await db.insert(messagesTable)
      .values({
        chat_id: input.chat_id,
        role: 'user',
        content: input.content,
        metadata: {
          tokens_used: Math.ceil(input.content.length / 4), // Rough token estimation
          processing_time_ms: 0
        }
      })
      .returning()
      .execute();

    const userMessage = userMessageResult[0];

    // 3. Simple content search in Nelson textbook (placeholder for vector search)
    // In real implementation, this would use embeddings and vector similarity
    const searchTerms = input.content.toLowerCase().split(' ').filter(term => term.length > 3);
    let nelsonResults: any[] = [];
    
    if (searchTerms.length > 0) {
      // Simple text search as placeholder for vector search
      const searchPattern = `%${searchTerms[0]}%`; // Use first meaningful term
      nelsonResults = await db.select()
        .from(nelsonContentTable)
        .where(ilike(nelsonContentTable.content, searchPattern))
        .limit(3)
        .execute();
    }

    // 4. Generate AI response (placeholder - would call Mistral API with context)
    const responseContent = `Based on pediatric medical knowledge${nelsonResults.length > 0 ? ' and relevant textbook content' : ''}, here's my response to: "${input.content}"\n\nThis is a placeholder response from NelsonGPT. In production, this would be generated by Mistral AI with context from Nelson's Textbook of Pediatrics.`;

    // 5. Create citations from search results
    const citations = nelsonResults.map((result, index) => ({
      source: `Nelson's Textbook of Pediatrics - ${result.chapter}`,
      page: result.page_number,
      chapter: result.chapter,
      content_snippet: result.content.substring(0, 200) + '...',
      relevance_score: 0.85 - (index * 0.1) // Placeholder relevance scores
    }));

    // 6. Save assistant response to database
    const processingTime = Date.now() - startTime;
    const tokensUsed = Math.ceil(responseContent.length / 4); // Rough estimation

    const assistantMessageResult = await db.insert(messagesTable)
      .values({
        chat_id: input.chat_id,
        role: 'assistant',
        content: responseContent,
        metadata: {
          citations: citations.map(c => ({
            source: c.source,
            page: c.page,
            chapter: c.chapter,
            relevance_score: c.relevance_score
          })),
          tokens_used: tokensUsed,
          processing_time_ms: processingTime,
          model_used: 'mistral-large'
        }
      })
      .returning()
      .execute();

    const assistantMessage = assistantMessageResult[0];

    // 7. Return complete AI response
    return {
      message: {
        id: assistantMessage.id,
        chat_id: assistantMessage.chat_id,
        role: assistantMessage.role as 'assistant',
        content: assistantMessage.content,
        metadata: assistantMessage.metadata as any,
        created_at: assistantMessage.created_at
      },
      citations,
      processing_time_ms: processingTime,
      tokens_used: tokensUsed
    };

  } catch (error) {
    console.error('Send message failed:', error);
    throw error;
  }
}
